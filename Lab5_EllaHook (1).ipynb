{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yz5RkPBON5YX",
        "outputId": "8897740d-36bc-4281-82e7-fdbbfda1c734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.10/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.10/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Structure:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 100 entries, 0 to 99\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype         \n",
            "---  ------        --------------  -----         \n",
            " 0   title         100 non-null    object        \n",
            " 1   score         100 non-null    int64         \n",
            " 2   id            100 non-null    object        \n",
            " 3   subreddit     100 non-null    object        \n",
            " 4   url           100 non-null    object        \n",
            " 5   num_comments  100 non-null    int64         \n",
            " 6   body          100 non-null    object        \n",
            " 7   created       100 non-null    datetime64[ns]\n",
            "dtypes: datetime64[ns](1), int64(2), object(5)\n",
            "memory usage: 6.4+ KB\n",
            "None\n",
            "\n",
            "DataFrame Contents:\n",
            "                                               title  score       id  \\\n",
            "0         Environmental Careers - 2024 Salary Survey     44  1e6lf9w   \n",
            "1  2024 Reddit Geologic and Environmental Careers...     31  1e6p3v9   \n",
            "2              Is this normal? Should I just leave?       3  1gqntve   \n",
            "3                           Starting Place for ES BA      4  1gqkuy5   \n",
            "4                                TCEQ Hiring Process      3  1gqkj0l   \n",
            "\n",
            "               subreddit                                                url  \\\n",
            "0  Environmental_Careers  https://www.reddit.com/r/Environmental_Careers...   \n",
            "1  Environmental_Careers  https://www.reddit.com/r/Environmental_Careers...   \n",
            "2  Environmental_Careers  https://www.reddit.com/r/Environmental_Careers...   \n",
            "3  Environmental_Careers  https://www.reddit.com/r/Environmental_Careers...   \n",
            "4  Environmental_Careers  https://www.reddit.com/r/Environmental_Careers...   \n",
            "\n",
            "   num_comments                                               body  \\\n",
            "0            26  # Intro:\\n\\nWelcome to the **fourth annual** [...   \n",
            "1             0  G’day folks of /r/Environmental_Careers,\\n\\nI ...   \n",
            "2             3  Hi all- I am nearing the end of my rope! I’ve ...   \n",
            "3             0  I am graduating soon with a ba in env studies....   \n",
            "4             4  For the TCEQ location in ATX, I was wondering ...   \n",
            "\n",
            "              created  \n",
            "0 2024-07-18 20:34:50  \n",
            "1 2024-07-18 23:17:08  \n",
            "2 2024-11-13 21:17:04  \n",
            "3 2024-11-13 19:12:33  \n",
            "4 2024-11-13 18:59:13  \n",
            "\n",
            "Post with the highest score:\n",
            "title                        Trump selects Lee Zeldin to lead EPA\n",
            "score                                                         439\n",
            "id                                                        1gp2yyf\n",
            "subreddit                                   Environmental_Careers\n",
            "url             https://thehill.com/homenews/administration/49...\n",
            "num_comments                                                   97\n",
            "body                                                             \n",
            "created                                       2024-11-11 20:57:15\n",
            "Name: 18, dtype: object\n",
            "\n",
            "Post with the least number of comments:\n",
            "title           2024 Reddit Geologic and Environmental Careers...\n",
            "score                                                          31\n",
            "id                                                        1e6p3v9\n",
            "subreddit                                   Environmental_Careers\n",
            "url             https://www.reddit.com/r/Environmental_Careers...\n",
            "num_comments                                                    0\n",
            "body            G’day folks of /r/Environmental_Careers,\\n\\nI ...\n",
            "created                                       2024-07-18 23:17:08\n",
            "Name: 1, dtype: object\n"
          ]
        }
      ],
      "source": [
        "!pip install praw\n",
        "\n",
        "import praw\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize PRAW with your Reddit application credentials\n",
        "reddit = praw.Reddit(\n",
        "    client_id='BmGfpxrgpA4U8yJZNl3Y2g',\n",
        "    client_secret='hAzVgiZAFzsIeLAAfE_yga9VQtElyg',\n",
        "    user_agent='My Reddit Data Scraper'\n",
        ")\n",
        "\n",
        "# Specify a subreddit\n",
        "chosen_sub = 'Environmental_Careers'\n",
        "\n",
        "# Fetch the top 100 hot posts from the subreddit\n",
        "posts_data = []\n",
        "for submission in reddit.subreddit(chosen_sub).hot(limit=100):\n",
        "    posts_data.append({\n",
        "        'title': submission.title,\n",
        "        'score': submission.score,\n",
        "        'id': submission.id,\n",
        "        'subreddit': submission.subreddit.display_name,\n",
        "        'url': submission.url,\n",
        "        'num_comments': submission.num_comments,\n",
        "        'body': submission.selftext,\n",
        "        'created': submission.created_utc  # UTC timestamp\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(posts_data)\n",
        "\n",
        "# Convert created time to a human-readable format\n",
        "df['created'] = pd.to_datetime(df['created'], unit='s')\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"DataFrame Structure:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataFrame Contents:\")\n",
        "print(df.head())\n",
        "\n",
        "# Which post has the highest scores?\n",
        "highest_score_post = df.loc[df['score'].idxmax()]\n",
        "\n",
        "# Which post has the least number of comments?\n",
        "least_comments_post = df.loc[df['num_comments'].idxmin()]\n",
        "\n",
        "# Display results\n",
        "print(\"\\nPost with the highest score:\")\n",
        "print(highest_score_post)\n",
        "print(\"\\nPost with the least number of comments:\")\n",
        "print(least_comments_post)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Which post has the highest scores?\n",
        "\n",
        "Trump selects Lee Zeldin to lead EPA\n",
        "\n",
        " Which post has the least number of comments?\n",
        "\n",
        " 2024 Reddit Geologic and Environmental Careers"
      ],
      "metadata": {
        "id": "LNvi8E2n6oxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install praw\n",
        "import praw\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize PRAW with your Reddit application credentials\n",
        "reddit = praw.Reddit(\n",
        "    client_id='BmGfpxrgpA4U8yJZNl3Y2g',\n",
        "    client_secret='hAzVgiZAFzsIeLAAfE_yga9VQtElyg',\n",
        "    user_agent='My Reddit Data Scraper'\n",
        ")\n",
        "\n",
        "# (a) Choose five subreddits\n",
        "subreddits = ['learnpython', 'dataisbeautiful', 'machinelearning', 'python', 'programming']\n",
        "\n",
        "# Function to scrape posts from a subreddit\n",
        "def scrape_subreddit(subreddit_name):\n",
        "    posts_data = []\n",
        "    for submission in reddit.subreddit(subreddit_name).hot(limit=100):\n",
        "        posts_data.append({\n",
        "            'title': submission.title,\n",
        "            'score': submission.score,\n",
        "            'id': submission.id,\n",
        "            'subreddit': subreddit_name,\n",
        "            'url': submission.url,\n",
        "            'num_comments': submission.num_comments,\n",
        "            'body': submission.selftext,\n",
        "            'created': submission.created_utc  # UTC timestamp\n",
        "        })\n",
        "    return posts_data\n",
        "\n",
        "# Scrape each subreddit\n",
        "all_posts = []\n",
        "for sub in subreddits:\n",
        "    all_posts.extend(scrape_subreddit(sub))\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(all_posts)\n",
        "\n",
        "# (b) Convert created time to a human-readable format\n",
        "df['created'] = pd.to_datetime(df['created'], unit='s')\n",
        "\n",
        "# (c) Create a new variable with three categories based on num_comments\n",
        "def categorize_comments(num_comments):\n",
        "    if num_comments < 50:\n",
        "        return 'low comment posts'\n",
        "    elif 51 <= num_comments <= 100:\n",
        "        return 'medium comment posts'\n",
        "    else:\n",
        "        return 'high comment posts'\n",
        "\n",
        "# Apply the function to create a new column\n",
        "df['comment_category'] = df['num_comments'].apply(categorize_comments)\n",
        "\n",
        "# Display the DataFrame\n",
        "print(\"DataFrame Structure:\")\n",
        "print(df.info())\n",
        "print(\"\\nDataFrame Contents:\")\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKdSxtOLmN98",
        "outputId": "ccc46940-8817-4aa0-ef93-503c397ec3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: praw in /usr/local/lib/python3.10/dist-packages (7.8.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.10/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Structure:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Data columns (total 9 columns):\n",
            " #   Column            Non-Null Count  Dtype         \n",
            "---  ------            --------------  -----         \n",
            " 0   title             500 non-null    object        \n",
            " 1   score             500 non-null    int64         \n",
            " 2   id                500 non-null    object        \n",
            " 3   subreddit         500 non-null    object        \n",
            " 4   url               500 non-null    object        \n",
            " 5   num_comments      500 non-null    int64         \n",
            " 6   body              500 non-null    object        \n",
            " 7   created           500 non-null    datetime64[ns]\n",
            " 8   comment_category  500 non-null    object        \n",
            "dtypes: datetime64[ns](1), int64(2), object(6)\n",
            "memory usage: 35.3+ KB\n",
            "None\n",
            "\n",
            "DataFrame Contents:\n",
            "                                               title  score       id  \\\n",
            "0                Ask Anything Monday - Weekly Thread      3  1goetp0   \n",
            "1                     Learn Python in the real world     10  1gqm4ny   \n",
            "2  Why doesn't this try/except prevent a user fro...      6  1gqoxkb   \n",
            "3  Okay, here it is. My attempt at blackjack as a...     59  1gq3xke   \n",
            "4  Executing with batch file not pulling .env var...      3  1gqlb78   \n",
            "\n",
            "     subreddit                                                url  \\\n",
            "0  learnpython  https://www.reddit.com/r/learnpython/comments/...   \n",
            "1  learnpython  https://www.reddit.com/r/learnpython/comments/...   \n",
            "2  learnpython  https://www.reddit.com/r/learnpython/comments/...   \n",
            "3  learnpython  https://www.reddit.com/r/learnpython/comments/...   \n",
            "4  learnpython  https://www.reddit.com/r/learnpython/comments/...   \n",
            "\n",
            "   num_comments                                               body  \\\n",
            "0            29  Welcome to another /r/learnPython weekly \"Ask ...   \n",
            "1            14  I want to learn Python, but my creative juices...   \n",
            "2             8  Hey all, I'm writing this program with a secti...   \n",
            "3            49  I know this is probably pretty bad. But how ba...   \n",
            "4             6  I'm trying to test a dummy script that sends a...   \n",
            "\n",
            "              created   comment_category  \n",
            "0 2024-11-11 00:00:34  low comment posts  \n",
            "1 2024-11-13 20:05:47  low comment posts  \n",
            "2 2024-11-13 22:03:34  low comment posts  \n",
            "3 2024-11-13 03:40:47  low comment posts  \n",
            "4 2024-11-13 19:31:17  low comment posts  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# df = pd.DataFrame({'column1': [1, 2, 3], 'column2': ['a', 'b', 'c']})\n",
        "\n",
        "# Save the DataFrame as a CSV file\n",
        "df.to_csv('exported_data.csv', index=False)\n",
        "\n",
        "# Download the CSV file\n",
        "files.download('exported_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "1SLXvtzD7jjD",
        "outputId": "3b47f243-49d3-480b-a67d-c2c9279d7762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-27d0267e3102>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Save the DataFrame as a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exported_data.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Download the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    }
  ]
}